{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5b9a4c-5020-4528-8904-cc266910e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 01: load libraries\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the code directory to sys.path\n",
    "sys.path.append(os.path.join(os.path.dirname(current_dir), 'code'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from google.cloud import bigquery # SQL table interface on Arcus\n",
    "from dxFilterLibraryPreGrading import *\n",
    "from reportMarkingFunctions import *\n",
    "from projectTableFunctions import * \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Initialize the client service\n",
    "client = bigquery.Client()\n",
    "\n",
    "req_table = \"lab.test_requested_sessions_main_with_metadata\"\n",
    "grader_table = \"lab.test_grader_table_with_metadata\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e092d3-5d6c-4f08-9bec-338b4efdeca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_grader_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060b70e7-3028-4646-b038-8411fb2e5365",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is about testing the process for adding multiple cohorts to individuals\n",
    "import json\n",
    "import os\n",
    "\n",
    "# check_table_for_cohort_includi\n",
    "table_name = \"lab.grader_table_with_metadata\"\n",
    "config_fn = \"/home/youngjm/bgdlab/code/annotation-helper-tools/queries/config.json\"\n",
    "\n",
    "# THIS IS A FUNCTION\n",
    "# Load the config file\n",
    "with open(config_fn, \"r\") as f:\n",
    "    dict_query = json.load(f)\n",
    "\n",
    "# The following is only for running on the grader_table_with_metadata, it \n",
    "# is not suited for running during report queuing yet\n",
    "for cohort in list(dict_query):\n",
    "    print(cohort)\n",
    "    # Load cohort config\n",
    "    q_cohort = load_cohort_config(cohort)\n",
    "    \n",
    "    # Modify the query to get any patient in the specified table\n",
    "    # who is identified with the query and the dx filter but not \n",
    "    # tagged with the cohort name \n",
    "    q_cohort_updated = \"with CTE as (\"+q_cohort.replace(';', ' ')+\") select my_tab.* from \"+table_name\n",
    "    q_cohort_updated +=' my_tab join CTE on my_tab.proc_ord_id = CTE.proc_ord_id where project not like \"%'+cohort\n",
    "    q_cohort_updated +='%\" and grader_name not like \"%Coarse Text Search%\"; '\n",
    "    \n",
    "    # Run the query to get the proc ord ids and their project names\n",
    "    df = client.query(q_cohort_updated).to_dataframe()\n",
    "    print(df.shape)\n",
    "    \n",
    "    # For each row in the dataframe\n",
    "    for idx, row in df.iterrows():\n",
    "        # Get the project column\n",
    "        proj = row['project']\n",
    "        projects = proj.replace(\"; \", \";\").split(\";\")\n",
    "        projects.append(cohort)\n",
    "        # Create the updated string for the project column \n",
    "        # -- Do I want this sorted alphabetically by project name?\n",
    "        updated_projects = \"; \".join(sorted(projects))\n",
    "        # Write the update query\n",
    "        q_update_projects = 'update '+table_name+' set project=\"'+updated_projects\n",
    "        q_update_projects += '\" where pat_id=\"'+row['pat_id']+'\" and proc_ord_id=\"'\n",
    "        q_update_projects += row['proc_ord_id']+'\" and grader_name=\"'+row['grader_name']+'\" ;'\n",
    "        job = client.query(q_update_projects)\n",
    "        job.result()\n",
    "\n",
    "print(\"Project Cohorts updated\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1eec5a-b7ad-4d88-88c4-b2f48fa569b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = '''select\n",
    "  pat_id,\n",
    "  proc_ord_id,\n",
    "  proc_ord_desc,\n",
    "  proc_ord_age,\n",
    "  proc_ord_year\n",
    "from\n",
    "  arcus.procedure_order\n",
    "where\n",
    "  proc_ord_desc like \"MR FETAL%\"\n",
    "order by proc_ord_age'''\n",
    "\n",
    "df = client.query(q).to_dataframe()\n",
    "df['age_in_years'] = df['proc_ord_age'].astype(int)/365.25\n",
    "\n",
    "plt.hist(df['age_in_years'], bins = 50)\n",
    "plt.title(\"Histogram of Age At Scan\")\n",
    "plt.xlabel(\"Age at Scan (years)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cfdf8ba-800b-499a-9a59-f576357b079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['proc_ord_year'], bins = 30)\n",
    "plt.title(\"Histogram of Year of Scan\")\n",
    "plt.xlabel(\"Year of Scan\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.grid(visible=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfde719-f31c-41f0-85b3-a6d9b90a1b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(list(df['pat_id'].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e1e34f-eb08-4ab1-9024-cb83ebb170cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "q = 'select pat_id, proc_ord_id, project from lab.grader_table_with_metadata where grade_date like \"%2024%\" ;'\n",
    "df = client.query(q).to_dataframe()\n",
    "print(df.shape)\n",
    "df = df.drop_duplicates()\n",
    "print(df.shape)\n",
    "\n",
    "projects = sorted(list(set(\"; \".join(list(set(df['project'].values))).split(\"; \"))))\n",
    "for project in projects:\n",
    "    if project != 'SLIP':\n",
    "        count = len(df[df['project'].str.contains(project)])\n",
    "        print(project, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77af3b2f-c70b-4e38-9850-18b7daa1623e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## And now for something completely different: going to make a separate lab.proc_ord_project table\n",
    "drop_table = \"DROP TABLE lab.proc_ord_projects\"\n",
    "job = client.query(drop_table)\n",
    "job.result()\n",
    "create_table = \"CREATE TABLE lab.proc_ord_projects (proc_ord_id STRING, pat_id STRING, project STRING)\"\n",
    "job = client.query(create_table)\n",
    "job.result()\n",
    "\n",
    "# Read the config file\n",
    "cfg_fn = \"./queries/config.json\"\n",
    "with open(cfg_fn, 'r') as f:\n",
    "    cfg = json.load(f)\n",
    "for cohort in cfg:\n",
    "    # Load the query for the cohort\n",
    "    print(cohort)\n",
    "    project_query = load_cohort_config(cohort)\n",
    "    # Get the pat/proc combos for the project\n",
    "    df = client.query(project_query).to_dataframe()[['proc_ord_id', 'pat_id']]\n",
    "    df = df.drop_duplicates()\n",
    "    # Add the pat/proc combos to the proc_ord_projects table\n",
    "    count = 0\n",
    "    add_projects_query = 'insert into lab.proc_ord_projects (proc_ord_id, pat_id, project) VALUES '\n",
    "    for idx, row in df.iterrows():\n",
    "        if count < 100:\n",
    "            add_projects_query += '(\"'+str(row['proc_ord_id'])+'\", \"'+str(row['pat_id'])+'\", \"'+cohort+'\"), '\n",
    "            count += 1\n",
    "        else:\n",
    "            add_projects_query = add_projects_query[:-2]+\";\"\n",
    "            job = client.query(add_projects_query)\n",
    "            job.result()\n",
    "            add_projects_query = 'insert into lab.proc_ord_projects (proc_ord_id, pat_id, project) VALUES '\n",
    "            count = 0\n",
    "    add_projects_query = add_projects_query[:-2]+\";\"\n",
    "    job = client.query(add_projects_query)\n",
    "    job.result()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e68623-822e-4c4b-87f9-32db17224adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next test: how many rows are in our new project table? how many unique pat_ids? for a cohort, are there any duplicate rows?\n",
    "\n",
    "# 1. How many rows are in our new project table\n",
    "q_rows = \"select proc_ord_id, pat_id, project from lab.proc_ord_projects\"\n",
    "df = client.query(q_rows).to_dataframe()\n",
    "print(df.shape)\n",
    "\n",
    "# 2. How many unique patients are in the table?\n",
    "q_rows = \"select distinct pat_id from lab.proc_ord_projects\"\n",
    "df = client.query(q_rows).to_dataframe()\n",
    "print(df.shape)\n",
    "\n",
    "# 3. How many unique rows are in the table?\n",
    "q_rows = \"select distinct proc_ord_id, pat_id, project from lab.proc_ord_projects\"\n",
    "df = client.query(q_rows).to_dataframe()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598db5a-0fdd-4419-b362-bb424440259b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next step: make copies of existing tables without the project columns.\n",
    "q_drop = \"drop table lab.test_grader_table_with_metadata\"\n",
    "job = client.query(q_drop)\n",
    "\n",
    "# grader table\n",
    "q_make_and_modify = \"create table lab.test_grader_table_with_metadata as \"\n",
    "q_make_and_modify += \"(select proc_ord_id, grader_name, grade, grade_category, \"\n",
    "q_make_and_modify += \"pat_id, age_in_days, proc_ord_year, proc_name, \"\n",
    "q_make_and_modify += \"report_origin_table, grade_date from lab.grader_table_with_metadata)\"\n",
    "job = client.query(q_make_and_modify)\n",
    "job.result()\n",
    "\n",
    "q_test = \"select * from lab.test_grader_table_with_metadata\"\n",
    "df = client.query(q_test).to_dataframe()\n",
    "print(df.shape)\n",
    "print(df.drop_duplicates().shape)\n",
    "\n",
    "# request table\n",
    "q_drop = \"drop table lab.test_requested_sessions_main_with_metadata\"\n",
    "job = client.query(q_drop)\n",
    "\n",
    "# No more modifications to this table as of 2024-10-21\n",
    "# q_make_and_modify = \"create table lab.test_requested_sessions_main_with_metadata as \"\n",
    "# q_make_and_modify += \"(select pat_id, proc_ord_id, proc_ord_age, proc_ord_year, \"\n",
    "# q_make_and_modify += \"proc_ord_desc, report_origin_table, grade_category, avg_grade, \"\n",
    "# q_make_and_modify += \"sex, race, ethnicity, dob_year, gestational_age_num, \"\n",
    "# q_make_and_modify += \"birth_weight_kg, birth_length_cm, request_label \"\n",
    "# q_make_and_modify += \"from lab.requested_sessions_main_with_metadata)\"\n",
    "# job = client.query(q_make_and_modify)\n",
    "# job.result()\n",
    "\n",
    "# q_test = \"select * from lab.test_requested_sessions_main_with_metadata\"\n",
    "# df = client.query(q_test).to_dataframe()\n",
    "# print(df.shape)\n",
    "# print(df.drop_duplicates().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ba3e3c-c951-415b-90d0-2459a3e79c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "cfg = \"./queries/config.json\"\n",
    "with open(cfg, \"r\") as f:\n",
    "    cohort_lookup = json.load(f)\n",
    "\n",
    "cohort_list = list(cohort_lookup.keys())\n",
    "print(cohort_list)\n",
    "\n",
    "# for cohort in cohort_list:\n",
    "#     print(cohort)\n",
    "#     add_reports_to_project(cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6690c9-a478-406d-8faa-1ab566035e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in cohort_list:\n",
    "    print()\n",
    "    get_project_report_stats(cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0d46c-27ad-41a1-9aef-7d7610cdd368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building functions to summarize data set status\n",
    "cohort = \"SLIP Toddlers\"\n",
    "\n",
    "# 1. How many reports exist and have been graded?\n",
    "get_project_report_stats(cohort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c98534-918b-4ffb-a4a8-c0efbd7bc88c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b1e228-ae4a-400f-bdcf-7b7d73ff42a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. What is the distribution of age at scan for \n",
    "# 2a. [x] for all cohort reports \n",
    "# 2b. [x] for requested reports\n",
    "# 2c. [x] split by grade \n",
    "# 2d. [x] split by sex\n",
    "\n",
    "plot_age_at_scan(cohort, color_by=['sex'], only_requested=True)\n",
    "\n",
    "# 3. When did the scans occur?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac6c083-fdec-4743-ac82-08bd6dfa6339",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cohort = get_unique_report_data(cohort, only_requested=False)\n",
    "df_cohort.head(10)\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, tight_layout=True)\n",
    "\n",
    "\n",
    "grades = list(set(df_cohort['avg_grade_group'].values))\n",
    "_, bin_edges = np.histogram(df_cohort['age_in_years'], 50)\n",
    "for grade in sorted(grades):\n",
    "    ax.hist(df_cohort[df_cohort['avg_grade_group'] == grade]['age_in_years'], \n",
    "                      bin_edges, histtype='bar', \n",
    "                      stacked=True, label=str(grade))\n",
    "\n",
    "\n",
    "plt.xlabel(\"Age at Scan (years)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.grid(visible=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c844708-aca0-4977-b023-21b6d7886620",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins = 50\n",
    "x = np.random.randn(1000, 3)\n",
    "print(len(x))\n",
    "print(len(x[0]))\n",
    "\n",
    "\n",
    "fig, ((ax0, ax1), (ax2, ax3)) = plt.subplots(nrows=2, ncols=2)\n",
    "\n",
    "colors_str = ['red', 'tan', 'lime']\n",
    "ax0.hist(x, n_bins, density=True, histtype='bar', color=colors_str, label=colors_str)\n",
    "ax0.legend(prop={'size': 10})\n",
    "ax0.set_title('bars with legend')\n",
    "\n",
    "ax1.hist(x, n_bins, density=True, histtype='bar', stacked=True)\n",
    "ax1.set_title('stacked bar')\n",
    "\n",
    "ax2.hist(x, n_bins, histtype='step', stacked=True, fill=False)\n",
    "ax2.set_title('stack step (unfilled)')\n",
    "\n",
    "# Make a multiple-histogram of data-sets with different length.\n",
    "x_multi = [np.random.randn(n) for n in [10000, 5000, 2000]]\n",
    "ax3.hist(x_multi, n_bins, histtype='bar')\n",
    "ax3.set_title('different sample sizes')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639281e5-30ac-47a3-b1a7-de8d971b58c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-arcus",
   "language": "python",
   "name": "conda-env-.conda-arcus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
