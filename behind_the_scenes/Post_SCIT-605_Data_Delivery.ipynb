{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c3a1d90-8847-40e6-b492-26f7e23842ff",
   "metadata": {},
   "source": [
    "# Post SCIT-605 Data Delivery Tests\n",
    "\n",
    "1. Add the most recent data delivery schema to the list of `arcus_deliveries`.\n",
    "2. Check for patients dropped between deliveries.\n",
    "3. Commit the updated `missing_patient_info.csv` table.\n",
    "4. Switch to Respublica and pull the updated table.\n",
    "5. Run `python check_data_deliveries.py` to check the data deliveries for any missing but requested patient ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2848446-3ebe-4517-84ad-73d5212c9d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b48a437-70e5-4d1f-844a-8d1d8b212a02",
   "metadata": {},
   "source": [
    "### 1. Add the most recent data delivery schema to the list of `arcus_deliveries`. In the past, I've had to ask for this specifically from the Arcus team member delivering the data. \n",
    "\n",
    "In the lab, there are 2 visible SQL schemas: `arcus` and `lab`. Tables delivered from Arcus are placed in the `arcus` schema. Tables we generate are placed in the `lab` schema. Previously delivered data from Arcus is archived into a schema following the naming convention `arcus_YYYY_MM_DD` where YYYY, MM, and DD are the 4 digit year, 2 digit month, and 2 digit day dates the data was originally delivered to the lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd5cf68-df82-4933-bd44-c1fc5cb9163d",
   "metadata": {},
   "outputs": [],
   "source": [
    "arcus_deliveries = [    \n",
    "    \"arcus_2023_04_05\",\n",
    "    \"arcus_2023_05_02\",\n",
    "    \"arcus_2023_10_23\",\n",
    "    \"arcus_2023_12_11\",\n",
    "    \"arcus_2024_02_13\",\n",
    "    \"arcus_2024_07_16\",\n",
    "    \"arcus_2025_02_11\",\n",
    "    \"arcus_2025_04_16\",\n",
    "]\n",
    "\n",
    "# search_username = \"Coarse Text Search 2025-04-28\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b177039e-73b8-4bed-9a02-112fcb69d591",
   "metadata": {},
   "source": [
    "### 2. Check for dropped patients\n",
    "\n",
    "In the past, patients sometimes are included in one Arcus data delivery but not the next. Reasons for a patient to be \"dropped\" vary from the family withdrew consent for the patient's data to be used in research to there was a clerical error assigning a scan belonging to one patient to the incorrect patient. There are not expected to be many of these patients but we would rather know ahead of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39269a49-3949-4d6d-bfba-c75e2cc57422",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_one_delivery(s_delivery_1, s_delivery_2):\n",
    "    '''\n",
    "    Compare the contents of the pat and procedure_order tables\n",
    "    from two delivery schemas\n",
    "    @param s_delivery_1 str name of one delivery schema\n",
    "    @param s_delivery_2 str name of second delivery schema\n",
    "    @return df_missing_pats dataframe containing patient id, \n",
    "            procedure order id, request label, and name of the\n",
    "            schema where they were no longer included\n",
    "    '''\n",
    "    # Initialize the client\n",
    "    client = bigquery.Client()\n",
    "\n",
    "    # SQL query to get the patients in schema 1 but not schema 2\n",
    "    query = \"\"\"with missing as (select \n",
    "        pat.pat_id, \n",
    "        proc.proc_ord_id,\n",
    "        '\"\"\"+s_delivery_2+\"\"\"' as missing_from_table\n",
    "      from\n",
    "        \"\"\"+s_delivery_1+\"\"\".patient pat\n",
    "        join \"\"\"+s_delivery_1+\"\"\".procedure_order proc on proc.pat_id = pat.pat_id\n",
    "      where\n",
    "        pat.pat_id not in (\n",
    "          select\n",
    "            pat_id\n",
    "          from\n",
    "            \"\"\"+s_delivery_2+\"\"\".patient\n",
    "        )\n",
    "      ) select\n",
    "          req.pat_id,\n",
    "          req.proc_ord_id,\n",
    "          request_label,\n",
    "          missing.missing_from_table\n",
    "        from\n",
    "          lab.requested_sessions_main_with_metadata req\n",
    "          join missing on req.pat_id = missing.pat_id\n",
    "          and req.proc_ord_id = missing.proc_ord_id\"\"\"\n",
    "    \n",
    "    # Run the query and get the results as a dataframe\n",
    "    df_missing_pats = client.query(query).to_dataframe()\n",
    "    \n",
    "    # Make a pretty printed summary\n",
    "    print(\"There are\", len(df_missing_pats[['pat_id', 'missing_from_table']].drop_duplicates()), \"requested patients who were in\", s_delivery_1, \"but were dropped in\", s_delivery_2)\n",
    "\n",
    "    return(df_missing_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8375138-ad75-48f9-8466-c410f87a467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dropped_patient_counts(arcus_deliveries):\n",
    "    '''\n",
    "    For every pair of delivery dates, identify patients who were included\n",
    "    in \n",
    "    '''\n",
    "    missing_pat_dfs = []\n",
    "    for i in range(len(arcus_deliveries)-1):\n",
    "        missing_pat_dfs.append(check_one_delivery(arcus_deliveries[i], arcus_deliveries[i+1]))\n",
    "\n",
    "    # Combine the list of missing patient info into a single df\n",
    "    df_dropped_pats = pd.concat(missing_pat_dfs, axis=0)\n",
    "    print()\n",
    "    print(\"Missing patient ids\")\n",
    "    for idx, row in df_dropped_pats[['pat_id', 'request_label']].drop_duplicates().iterrows():\n",
    "        print(row['pat_id'], row['request_label'])\n",
    "    return(df_dropped_pats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94393b0c-a89f-4b4e-9406-3ada6e807c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_dropped_patient_counts(arcus_deliveries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc91489-8e1d-44d7-a90c-ff22a5494f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"./missing_patient_info.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a41364f4-2001-459f-bdb0-b0736ef5e94f",
   "metadata": {},
   "source": [
    "## Update Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d40f9e-ae7f-41c6-8706-ac3275fad12a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d349f89b-1648-46e8-8fb2-a5647e2b2cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the config\n",
    "cfg = \"../queries/config.json\"\n",
    "with open(cfg, \"r\") as f:\n",
    "    cohort_lookup = json.load(f)\n",
    "\n",
    "cohort_list = list(cohort_lookup.keys())\n",
    "print(cohort_list)\n",
    "\n",
    "# To make sure all reports for all cohorts are indexed in the project table, \n",
    "# uncomment the for loop and its contents before running this cell. \n",
    "# Warning: it will take time to run, do not panic.\n",
    "for cohort in cohort_list:\n",
    "    print(cohort)\n",
    "    add_reports_to_project(cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181caa1e-7fa2-4ceb-93e4-b2316a58badb",
   "metadata": {},
   "source": [
    "## Apply the Coarse Text Search Filter\n",
    "Previously, a coarse text search was used to grade reports containing certain substrings indicating severe pathology as 0 to prevent them from being added to grader queues. The code for this step still exists in the notebook but has been commented out since the addition of Maryam Denaliâ€™s NLP models. Whether or not to run the coarse text search is up for further discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623727e-137c-489f-bcca-8cb039f8f20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = '''insert into\n",
    "#   lab.grader_table_with_metadata (\n",
    "#     proc_ord_id,\n",
    "#     grader_name,\n",
    "#     grade,\n",
    "#     grade_category,\n",
    "#     pat_id,\n",
    "#     age_in_days,\n",
    "#     proc_ord_year,\n",
    "#     proc_name,\n",
    "#     report_origin_table,\n",
    "#     project\n",
    "#   ) with CTE as (\n",
    "#     select\n",
    "#       proc.proc_ord_id,\n",
    "#       \"''' + search_username + '''\" as grader_name,\n",
    "#       0 as grade,\n",
    "#       \"Unique\" as grade_category,\n",
    "#       proc.pat_id,\n",
    "#       proc.proc_ord_age as age_in_days,\n",
    "#       proc.proc_ord_year,\n",
    "#       proc.proc_ord_desc as proc_name,\n",
    "#       \"arcus.procedure_order\" as report_origin_table,\n",
    "#       \"SLIP\" as project\n",
    "#     from\n",
    "#       arcus.procedure_order proc\n",
    "#       inner join arcus.procedure_order_narrative txt on proc.proc_ord_id = txt.proc_ord_id\n",
    "#     where\n",
    "#       proc.proc_ord_desc like \"%BRAIN%\"\n",
    "#       and (\n",
    "#         txt.narrative_text like \"%hemotherapy%\"\n",
    "#         or txt.narrative_text like \"%resect%\"\n",
    "#         or txt.narrative_text like \"%Resect%\"\n",
    "#         or txt.narrative_text like \"%raniotomy%\"\n",
    "#         or txt.narrative_text like \"%raniectomy%\"\n",
    "#         or txt.narrative_text like \"%urgical cavity%\"\n",
    "#         or txt.narrative_text like \"%ost surg%\"\n",
    "#         or txt.narrative_text like \"%ostsurg%\"\n",
    "#         or txt.narrative_text like \"%ost-surg%\"\n",
    "#       )\n",
    "#   )\n",
    "# select\n",
    "#   *\n",
    "# from\n",
    "#   CTE;'''\n",
    "\n",
    "# client = bigquery.Client()\n",
    "\n",
    "# job = client.query(q)\n",
    "# job.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60233070-f678-4fe2-8062-23e3b58057a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-arcus",
   "language": "python",
   "name": "conda-env-.conda-arcus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
