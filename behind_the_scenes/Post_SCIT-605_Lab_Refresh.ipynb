{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34514e14-0652-420e-b545-929631b89c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the code directory to sys.path\n",
    "sys.path.append(os.path.join(os.path.dirname(current_dir), 'code'))\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from IPython.display import clear_output\n",
    "from google.cloud import bigquery # SQL table interface on Arcus\n",
    "from dxFilterLibraryPreGrading import *\n",
    "from reportMarkingFunctions import *\n",
    "from projectTableFunctions import * \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "\n",
    "# Initialize the client service\n",
    "client = bigquery.Client()\n",
    "backup_grader_table()\n",
    "\n",
    "grader_table_name = \"lab.grader_table_with_metadata_project_independent\"\n",
    "project_table_name = \"lab.proc_ord_projects\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f45201-7e8b-4711-82da-8b985bacf550",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Update Phecodes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb6d7fc-15ea-42c8-ae21-c456b98ef3a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Create a table containing all patient dx as phecodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58705e07-0b14-425a-ae04-e653b7f9bcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the table for patient phecodes\n",
    "table_all_patients = \"arcus.patient\"\n",
    "df_patient_phecodes = map_proc_req_to_phecodes(table_all_patients)\n",
    "df_patient_phecodes.dtypes\n",
    "df_patient_phecodes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5dc6a3-7c47-41a4-9473-e4c21dabb76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patient_phecodes = df_patient_phecodes.drop(\"dx_source\", axis = 1)\n",
    "df_patient_phecodes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375c322c-a860-4ffc-bcc7-71a4157a1b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = \"lab.patient_phecode_dx\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        bigquery.SchemaField(\"pat_id\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"encounter_id\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"icd10cm\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"icd10cm_str\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"phecode_str\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f6257-dd2e-4d72-81a5-107e689c22bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = client.load_table_from_dataframe(\n",
    "    df_patient_phecodes, table_id, job_config=job_config\n",
    ")  # Make an API request.\n",
    "job.result()  # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ba6943-ee6c-4d39-9179-2dd98f5a76ba",
   "metadata": {},
   "source": [
    "## Update Projects to Include New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cfc3d23-0fd2-4575-83ae-0c996656d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure all reports for all cohorts are indexed in the project table, \n",
    "# uncomment the for loop and its contents before running this cell. \n",
    "# Warning: it will take time to run, do not panic.\n",
    "cfg = \"../queries/config.json\"\n",
    "with open(cfg, \"r\") as f:\n",
    "    cohort_lookup = json.load(f)\n",
    "\n",
    "cohort_list = list(cohort_lookup.keys())\n",
    "print(cohort_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8da69b6-8cc0-47a1-bb52-1b3db545381c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cohort in cohort_list:\n",
    "    print(cohort)\n",
    "    add_reports_to_project(cohort)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b410fc8d-7498-44a8-92e4-8cc2a490c684",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Incorporate NLP Grades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40ab4f4-0787-450a-87e8-e5620c33730d",
   "metadata": {},
   "source": [
    "### Check that the latest NLP Models have all missing proc_ord_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c109a230-e336-4114-914a-cc679fbaec2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there are no missing proc_ord_ids from new NLP delivery\n",
    "q_get_proc_ord_ids = \"SELECT proc_ord_id FROM arcus.procedure_order_narrative\"\n",
    "df_proc_ord_ids = client.query(q_get_proc_ord_ids).to_dataframe()\n",
    "\n",
    "q_get_new_nlp_grades = '''\n",
    "select\n",
    "    proc_ord_id,\n",
    "    majority_vote\n",
    "  from\n",
    "    lab.maryam_tmp_results_feb28_2025 nlp_predict'''\n",
    "\n",
    "df_new_nlp = client.query(q_get_new_nlp_grades).to_dataframe()\n",
    "\n",
    "q_get_old_nlp_grades = '''\n",
    "select\n",
    "    proc_ord_id,\n",
    "    majority_vote\n",
    "  from\n",
    "    lab.nlp_combined nlp_predict'''\n",
    "\n",
    "df_old_nlp = client.query(q_get_old_nlp_grades).to_dataframe()\n",
    "\n",
    "print(df_proc_ord_ids.shape)\n",
    "print(df_new_nlp.shape)\n",
    "\n",
    "print(\"Proc Ord IDs NOT in newly delivered NLP grades:\")\n",
    "print(sum(~df_proc_ord_ids.proc_ord_id.isin(list(df_new_nlp['proc_ord_id'].values))))\n",
    "print(\"Proc Ord IDs NOT in previously delivered NLP grades:\")\n",
    "print(sum(~df_proc_ord_ids.proc_ord_id.isin(list(df_old_nlp['proc_ord_id'].values))))\n",
    "print(\"Proc Ord IDs NOT in any delivered NLP grades:\")\n",
    "print(sum(~df_proc_ord_ids.proc_ord_id.isin(list(df_old_nlp['proc_ord_id'].values)) &\n",
    "          ~df_proc_ord_ids.proc_ord_id.isin(list(df_new_nlp['proc_ord_id'].values))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0246b12a-655b-4107-83dc-22aeae468443",
   "metadata": {},
   "source": [
    "### Update NLP Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b353be-1033-4462-914e-3faf221fe10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make backup of NLP grades\n",
    "q_create_backup = '''\n",
    "create table lab.bak_2025_03_03_nlp_combined as \n",
    "select * \n",
    "from lab.nlp_combined\n",
    "'''\n",
    "\n",
    "j_backup = client.query(q_create_backup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dc8dee-b565-4b94-b9c0-23697127a7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that backup exists and is the same as original\n",
    "q_check_backup = '''\n",
    "select * \n",
    "from lab.bak_2025_03_03_nlp_combined\n",
    "'''\n",
    "\n",
    "df_backup = client.query(q_check_backup).to_dataframe().sort_values(by = [\"proc_ord_id\",\"timestamp\"]).reset_index(drop = True)\n",
    "\n",
    "q_check_orig = '''\n",
    "select * \n",
    "from lab.nlp_combined\n",
    "'''\n",
    "\n",
    "df_orig = client.query(q_check_orig).to_dataframe().sort_values(by = [\"proc_ord_id\",\"timestamp\"]).reset_index(drop = True)\n",
    "\n",
    "print(df_backup.head())\n",
    "print(df_backup.shape)\n",
    "\n",
    "print(df_orig.head())\n",
    "print(df_orig.shape)\n",
    "\n",
    "df_backup.equals(df_orig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec770f75-cf56-4084-9543-106beb662f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge new grades with lab.nlp_combined\n",
    "q_insert = '''insert into lab.nlp_combined\n",
    "    select\n",
    "      *,\n",
    "      \"out_of_sample\" as exp_type\n",
    "    from\n",
    "      lab.maryam_tmp_results_feb28_2025;'''\n",
    "\n",
    "j_insert = client.query(q_insert)\n",
    "j_insert.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965a60c5-7daa-49c8-9257-4c7963b03b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_get_all_nlp_grades = '''\n",
    "select\n",
    "    proc_ord_id,\n",
    "    majority_vote\n",
    "  from\n",
    "    lab.nlp_combined nlp_predict'''\n",
    "\n",
    "df_all_nlp = client.query(q_get_all_nlp_grades).to_dataframe()\n",
    "\n",
    "print(df_all_nlp.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38da0a6-e657-4763-ad8e-5cfe92cdffcb",
   "metadata": {},
   "source": [
    "### Incorporate NLP Grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677c781-6ffa-4c57-94ca-7aac7f5cdd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get only reports where all 4 models agree 100%\n",
    "q_nlp =  '''\n",
    "with agreement as (\n",
    "  select\n",
    "    proc_ord_id,\n",
    "    majority_vote\n",
    "  from\n",
    "    lab.nlp_combined nlp_predict\n",
    "  where\n",
    "    nlp_predict.bert = nlp_predict.biobert\n",
    "    and nlp_predict.bert = nlp_predict.clinbert\n",
    "    and nlp_predict.bert = nlp_predict.radbert\n",
    "    and nlp_predict.bert = 2\n",
    ")\n",
    "select\n",
    "  agreement.proc_ord_id,\n",
    "  agreement.majority_vote,\n",
    "  pat.sex,\n",
    "  pat.race,\n",
    "  pat.dob_year,\n",
    "  proc_ord.proc_ord_year,\n",
    "  proc_ord.start_datetime,\n",
    "  proc_ord.proc_ord_age,\n",
    "  proc_ord.proc_ord_desc\n",
    "from\n",
    "  arcus.procedure_order proc_ord\n",
    "  join agreement on agreement.proc_ord_id = proc_ord.proc_ord_id\n",
    "  join arcus.patient pat on pat.pat_id = proc_ord.pat_id\n",
    "where\n",
    "  proc_ord.proc_ord_desc not like \"%SPECTROSCOPY%\"\n",
    "  and proc_ord.proc_ord_desc not like \"%OUTSIDE%\"\n",
    "  and proc_ord.proc_ord_desc not like \"%FUNCTL%\"\n",
    "  and proc_ord.proc_ord_desc not like \"%METABOLIC%\"\n",
    "  and proc_ord.proc_ord_desc not like \"%AUTOPSY%\"\n",
    "  and (\n",
    "    proc_ord.proc_ord_desc like \"%BRAIN%\"\n",
    "    or proc_ord.proc_ord_desc like \"%NEURO%\"\n",
    "  )\n",
    "order by\n",
    "  start_datetime desc\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bb032f-3339-4b0e-9dae-e6188dc7e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_reports_for_nlp(nlp_query, grader_name=\"NLP Models 2025-03-03\", project_id=\"\", dry_run = False):\n",
    "    client = bigquery.Client()\n",
    "    global grader_table_name\n",
    "\n",
    "    if not grader_name.startswith(\"NLP Models\"):\n",
    "        raise ValueError('grader_name must start with \"NLP Models\". This is essential to ensure that NLP reports graded on different sessions still match (e.g., \"NLP Models 2024-12-05\" and \"NLP Models 2025-02-20\"')\n",
    "    \n",
    "    # Get the column names from the table\n",
    "    q_get_cols = \"select * from \"+grader_table_name+\" limit 1;\"\n",
    "    df_get_cols = client.query(q_get_cols).to_dataframe()\n",
    "    cols_str = \" (\"+\", \".join(list(df_get_cols))+\") \"\n",
    "    \n",
    "    # Run the nlp query\n",
    "    df_nlp = client.query(nlp_query).to_dataframe()\n",
    "    print(list(df_nlp))\n",
    "\n",
    "    # Get the dataframe of reports already in the grader table\n",
    "    q_get_existing_nlp_grades = 'select * from '+grader_table_name+' where grader_name LIKE \"NLP Models%\";'\n",
    "    df_existing = client.query(q_get_existing_nlp_grades).to_dataframe()\n",
    "\n",
    "    # Get rid of rows in df_nlp if already in grader table\n",
    "    print(df_nlp.shape[0], \"NLP grades exist\")\n",
    "    df_nlp = df_nlp[~df_nlp['proc_ord_id'].isin(list(df_existing['proc_ord_id'].values))]\n",
    "    print(df_nlp.shape[0], \"NLP grades to be added\")\n",
    "\n",
    "    # Divide NLP grades into 100 report chunks\n",
    "    chunk_size = 100\n",
    "    num_chunks = df_nlp.shape[0] // chunk_size + 1\n",
    "    chunks = []\n",
    "    \n",
    "    # For each proc_ord_id \n",
    "    for i in tqdm(range(num_chunks)):\n",
    "        start_i = i * chunk_size\n",
    "        end_i = min((i + 1) * chunk_size, df_nlp.shape[0])\n",
    "        proc_ord_ids = df_nlp.proc_ord_id.iloc[start_i:end_i]\n",
    "        grades = \"2\"\n",
    "        # Set up the query\n",
    "        q_insert = f'''insert into {grader_table_name} {cols_str}\n",
    "            select\n",
    "              distinct \n",
    "              proc_ord.proc_ord_id, \"{grader_name+}\" as grader_name,\n",
    "              {grades} as grade,\n",
    "              \"Unique\" as grade_category,\n",
    "              proc_ord.pat_id,\n",
    "              proc_ord.proc_ord_age as age_in_days,\n",
    "              proc_ord.proc_ord_year,\n",
    "              proc_ord.proc_ord_desc as proc_name,\n",
    "              \"arcus.procedure_order\" as report_origin_table, \n",
    "              \"2025-03-03\" as grade_date, \n",
    "              \"SLIP\" as grade_criteria \n",
    "            from\n",
    "              arcus.procedure_order proc_ord\n",
    "              join arcus.patient pat on proc_ord.pat_id = pat.pat_id\n",
    "            where\n",
    "              proc_ord.proc_ord_id IN (\"'''+'\", \"'.join(proc_ord_ids)+'''\")\n",
    "            order by \n",
    "              proc_ord.proc_ord_year desc;'''\n",
    "        if dry_run:\n",
    "            print(q_insert)\n",
    "            break\n",
    "        else:\n",
    "            j_insert = client.query(q_insert)\n",
    "            j_insert.result()\n",
    "\n",
    "    print(len(df_nlp), \"reports for\", grader_name, \"added to\", grader_table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715cd065-420c-4ee1-8c13-94225c6bccae",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_reports_for_nlp(q_nlp, dry_run = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19541b9d-8465-4d1a-9f7f-e392419a6da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_reports_for_nlp(q_nlp, dry_run = False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
