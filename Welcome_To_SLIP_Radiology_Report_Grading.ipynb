{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8bea771c-44fc-4071-8c7a-34db1c849250",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## SLIP Radiology Report Grading Welcome\n",
    "\n",
    "Welcome to the SLIP project. The project was started with the intention to curate a set of clinically acquired Scans with Limited Imaging Pathology. The ongoing retrospective data collection process begins with checking the radiology reports (semi-structured written summaries of the contents of a scan). Because these scans are clinically acquired, a scan with no pathology cannot be marked as \"healthy\". Rather, scans are often marked as \"unremarkable\" or \"appearing normal\" to indicate a lack of finding. \n",
    "\n",
    "The training for SLIP report grading has 3 steps:\n",
    "1. Reading SLIP and non-SLIP report examples\n",
    "2. Practicing rating a subset of 150 reports\n",
    "3. Grade a set of \"shared\" reports used for calculating reliability ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df822d-ea71-49f2-9c3b-65c1fda1f60c",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Grading Guidelines\n",
    "\n",
    "The grades are on an ordinal scale of 0/1/2 where\n",
    "- Rating 0: Suspect serious imaging pathology\n",
    "- Rating 1: Neither a 0 nor a 2 (AKA “I don’t know”). These are people who may or may not be included in our analyses depending on the context.\n",
    "- Rating 2: No reason to suspect imaging pathology. These are people whose imaging pathology would likely not exclude them from being part of a control cohort in research brain MRI study. Note that this is different from their PAST MEDICAL HISTORY potentially excluding them, which is a different issue.\n",
    "\n",
    "**Before starting to examine reports, read through the report grading guidelines\n",
    "[HERE](https://docs.google.com/document/d/1MJpBa2z43dxVkjgO-QSDjb9ubItYJkUw/edit?tab=t.0).** If you would like to add a phrase, please leave a comment in the document in the corresponding section containing the phrase and how it should be interpreted."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c5cf41-0e41-4bf9-969c-950f62bd44e8",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Step 0: Run the following cell to load the necessary libraries and set up variables.\n",
    "\n",
    "Then scroll down to Step 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4f32ce-c048-4148-a979-6b6ff2d436d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 0 - must be run first!\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the code directory to sys.path\n",
    "sys.path.append(os.path.join(current_dir, 'code'))\n",
    "\n",
    "\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from annotationHelperLib import *\n",
    "from reportMarkingFunctions import *\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# This variable is a list of words that will be highlighed in yellow in the reports. \n",
    "# To add a specific string to the list, enclose it in single or double quotes and follow it\n",
    "# with a comma\n",
    "\n",
    "toHighlight = phrasesToHighlightFn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64eb79b6-f6d9-4c6a-b541-62b096b992e0",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Step 1: Reading Example Reports\n",
    "\n",
    "Run the following cell to view each sample report and its categorization as SLIP or non-SLIP. Press 'enter' after reading the report to view another report. When the cell finishes running, you can rerun it to view the reports again or proceed to the next section if you are comfortable with your understanding of the reports.\n",
    "\n",
    "The argument `toHighlight` passes a dictionary with color strings as keys and lists of strings as values to the function. The function will highlight occurrences of strings in each list in the specified color. (Note: you can modify the lists included in this dictionary as you wish. The highlighting is imperfect, but it helps draw your eye to phrases that are meaningful to you.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d7af3b-8681-4813-8e47-aa76f3376fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 01\n",
    "read_sample_reports(toHighlight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b1e15-e0bb-44ed-9db1-4a7e3e79dc2f",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Step 2: Self-Evaluation Practice for Report Grading\n",
    "\n",
    "In this section, you will practice rating reports yourself. Modify the variable `name` in the next cell to the name you use for publications. Then run the following cell to display a report, give it a grade, and note the reason you think it should get that grade. After your reasoning is submitted, the grades and reasons for the grades others have submitted will be shown. \n",
    "\n",
    "You can grade several reports while running the cell once. To change the number of reports in a batch, modify the variable `batchSize`.\n",
    "\n",
    "*If the report disappears after you type a number for the grade, use Ctrl + z or Cmd + z to undo, interrupt the kernel using the square button in the toolbar above, and run the cell again.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8e20d5-6609-4869-bf9e-8a5ee4eefefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 02\n",
    "# Replace with the name you want used in publications of this data set\n",
    "name = \"TEST\"\n",
    "batchSize = 30\n",
    "\n",
    "status = welcome_user(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3d045b-4d07-41fd-8295-5e8eca2ce480",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 03\n",
    "for i in range(batchSize):\n",
    "    clear_output()\n",
    "    print(i)\n",
    "    print()\n",
    "    if status == \"self-eval\":\n",
    "        mark_selfeval_report_sql(name, toHighlight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a255659a-87ad-4ca8-9880-fb94195459b6",
   "metadata": {
    "editable": false,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Step 3: Reliability Grading\n",
    "\n",
    "Now you can switch to the Arcus_Radiology_Report_Grading.ipynb notebook for the reliability reports. In the reliability report grading section, you will grade 150 reports that all other graders have also graded without real time feedback. At the end, we will assess your reliability with other graders."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
