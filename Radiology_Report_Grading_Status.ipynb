{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "905b178c-5679-4cb2-bf95-45eb72919c2d",
   "metadata": {},
   "source": [
    "## Purpose of this notebook\n",
    "\n",
    "- Examine similarities and differences between different raters' reliability report grades\n",
    "- Calculate Cohen's kappa between pairs of raters\n",
    "- Identify and print reports where raters strongly disagree (grade of 2 vs grade of 0)\n",
    "\n",
    "## How to use this notebook\n",
    "\n",
    "- Run each of the cells in order. Make sure you run Cell 01 first.\n",
    "- Cell 02 can be used to see how many reports have been graded since a date (YYYY-MM-DD format)\n",
    "- Cells 03-04 get the proc_ord_id values unique to each report and the names of the persons who have graded reliability reports.\n",
    "- Cell 05 can be used to examine the reports a pair of graders disagree on\n",
    "- Cells 06 will release examined reports back to a specified grader for regrading\n",
    "- Cell 07 can be used to examine and regrade reports marked with a -1 flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414b9366-e7f7-49cd-a5f4-2d26e7b32805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 01: load libraries\n",
    "import os\n",
    "\n",
    "# Get the current working directory\n",
    "current_dir = os.getcwd()\n",
    "\n",
    "# Add the code directory to sys.path\n",
    "sys.path.append(os.path.join(current_dir, 'code'))\n",
    "\n",
    "from reliabilityLib import *\n",
    "from reportMarkingFunctions import *\n",
    "from google.cloud import bigquery # SQL table interface on Arcus\n",
    "import pandas\n",
    "import numpy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "client = bigquery.Client()\n",
    "backup_grader_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a01a983-0da0-4b6c-bcc7-5a5c2ecd8212",
   "metadata": {},
   "source": [
    "## Evolution of SLIP over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00fd89a-f6d9-4d6d-bc27-e347475ca344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 02:\n",
    "get_grade_counts_since(\"2024-10-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eaa6b3-174e-4e3d-8657-95d3439be578",
   "metadata": {},
   "source": [
    "## Grader agreement on reliability reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd475e76-cb5d-483c-8ff3-d642c5056086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 03: Get the list of proc_ord_id values used to identify the reliability reports\n",
    "procIds = get_reliability_proc_ord_ids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bbf07-af1f-47fc-854e-2a03b608a9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 04: Compare the reliability reports for the users we want to evaluate\n",
    "graders = ['Jenna Schabdach', \n",
    "           'Megan M. Himes', \n",
    "           # 'Naomi Shifman', \n",
    "           # 'Alexa DeJean',\n",
    "           # 'Julia Katowitz',\n",
    "           'Matt Buczek',\n",
    "           'Shivaram Karandikar',\n",
    "           'Dabriel Zimmerman',\n",
    "           # 'Shreya Gudapati',\n",
    "           'Harry Hearn', \n",
    "           'Sepp Kohler', \n",
    "           'Eren Kafadar', \n",
    "           'Leila Abdel-Qader', \n",
    "           'Laura Mercedes', \n",
    "           'Zhiqiang Sha',\n",
    "           'Benjamin Jung']\n",
    "\n",
    "# Metric options: \"disagreement\", \"kappa\", \"kappa2vAll\", \"kappa0vAll\"\n",
    "df = calculate_metric_for_graders(graders, \"kappa\")\n",
    "print()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b2137aa-e029-4105-bc78-1ee0bd389fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 05: \n",
    "# This is the cell where you can look at the disagreement reports for each pair of users\n",
    "# User 1: Naomi\n",
    "# User 2: Jenna\n",
    "grader1 = \"Jenna Schabdach\"\n",
    "grader2 = \"Dabriel Zimmerman\"\n",
    "procIds = get_reliability_proc_ord_ids()\n",
    "grades1 = get_reports_for_user(grader1, procIds)\n",
    "grades2 = get_reports_for_user(grader2, procIds)\n",
    "# grades2 = grades1.copy(deep=True)\n",
    "# grades2['grade'] = [random.randint(0, 2) for i in range(len(grades1))]\n",
    "# grades2['grade'] = [ 0 for i in range(len(grades1)) ]\n",
    "disagreement = identify_disagreement_reports(grades1, grades2)\n",
    "print(len(disagreement))\n",
    "\n",
    "calc_kappa(grades1, grades2)\n",
    "\n",
    "# print_disagreement_reports(disagreement, grades1, grades2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e5e99-88a2-4867-b961-b1b7925cb572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 06: release a set of your reports back into your queue \n",
    "# ONLY USE THIS IF YOU'RE CERTAIN\n",
    "# release_reports(grader2, disagreement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99bcb3bf-3171-4992-8238-09f123ab2b52",
   "metadata": {},
   "source": [
    "## Release reports of retired graders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2cd68b-6164-4e22-b96f-8f40098aa55c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Edit this list to include the username of anyone who is actively grading\n",
    "# active_graders = ['Jenna Schabdach', \n",
    "#                   'Harry Hearn', \n",
    "#                   'Dabriel Zimmerman', \n",
    "#                   'Sepp Kohler', \n",
    "#                   'Megan M. Himes', \n",
    "#                   'Eren Kafadar', \n",
    "#                   'Matt Buczek', \n",
    "#                   'Leila Abdel-Qader', \n",
    "#                   'Laura Mercedes', \n",
    "#                   'Benjamin Jung', \n",
    "#                   'Zhiqiang Sha', \n",
    "#                   'Shivaram Karandikar']\n",
    "\n",
    "# # Run this cell once with the following flag set to True to check your grader list\n",
    "# just_check = True\n",
    "\n",
    "# # Get the list of graders\n",
    "# q = \"select distinct grader_name from lab.grader_table_with_metadata;\"\n",
    "# graders = client.query(q).to_dataframe()['grader_name'].values\n",
    "\n",
    "# # Drop \"Coarse Text Search\"\n",
    "# graders = [i for i in graders if \"Coarse Text Search\" not in i]\n",
    "# print(graders)\n",
    "\n",
    "# # For every grader\n",
    "# for grader in graders:\n",
    "#     # If the grader is no longer active\n",
    "#     if grader not in active_graders:\n",
    "#         # Get the number of reports in their queue\n",
    "#         q = 'select * from lab.grader_table_with_metadata where grader_name = \"'+grader+'\" and grade = 999 and grade_category = \"Unique\"'\n",
    "#         grader_df = client.query(q).to_dataframe()\n",
    "#         # Print the number of reports for the user\n",
    "#         print(grader, grader_df.shape)\n",
    "#         # Eventually, delete those entries\n",
    "#         if len(grader_df) > 0 and just_check = False:\n",
    "#             q = 'delete from lab.grader_table_with_metadata where grader_name = \"'+grader+'\" and grade = 999 and grade_category = \"Unique\"' \n",
    "#             job = client.query(q)\n",
    "#             job.result()ðŸŸ¢"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8decd41f-9a0a-4288-bff3-12048af671ac",
   "metadata": {},
   "source": [
    "## Examine flagged reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e88f41-a95f-4f30-9181-5e0c301b04fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 07: regrade skipped reports\n",
    "# client: A bigquery client object (created in Cell 01)\n",
    "# skippedGrader: A string of the grader's name (leave blank to review all flagged reports)\n",
    "skippedGrader = \"\" # \"Naomi Shifman\"\n",
    "regrade_skipped_reports(client, grader=skippedGrader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c516ecf6-151d-401e-bfd8-58a2778075d9",
   "metadata": {},
   "source": [
    "## For clinician review only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598ae063-e620-4aad-83bb-d363fa54f801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 08: clinician regrade skipped reports\n",
    "# client: A bigquery client object (created in Cell 01)\n",
    "# skippedGrader: A string of the grader's name (leave blank to review all flagged reports)\n",
    "regrade_skipped_reports(client, flag=-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216582c0-38aa-44f8-b1cf-c27ab6564b35",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda-arcus",
   "language": "python",
   "name": "conda-env-.conda-arcus-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
