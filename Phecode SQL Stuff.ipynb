{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47359b5a-a544-41b4-92de-0db53a029773",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from dxFilterLibraryPreGrading import *\n",
    "\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1bf8327-6171-46ab-9e83-c1fe4ca44f84",
   "metadata": {},
   "source": [
    "## Create the phecode lookup table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e03956a8-6240-4c6c-8d38-0504cf91bbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['icd10cm', 'icd10cm_str', 'phecode', 'phecode_str', 'exclude_range', 'exclude_name', 'leaf', 'rollup']\n"
     ]
    }
   ],
   "source": [
    "# Load the phecodes file\n",
    "fn_phecodes = \"/home/youngjm/private_transfer/ICDexclusion_code/Phecode_map_v1_2_icd10cm_beta.csv\"\n",
    "df_phecodes = pd.read_csv(fn_phecodes, encoding=\"unicode_escape\")\n",
    "print(list(df_phecodes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0c434501-d792-4455-9520-a41c4ecf9c63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>icd10cm</th>\n",
       "      <th>icd10cm_str</th>\n",
       "      <th>phecode</th>\n",
       "      <th>phecode_str</th>\n",
       "      <th>exclude_range</th>\n",
       "      <th>exclude_name</th>\n",
       "      <th>leaf</th>\n",
       "      <th>rollup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34114</th>\n",
       "      <td>Q85.02</td>\n",
       "      <td>Neurofibromatosis, type 2</td>\n",
       "      <td>199.4</td>\n",
       "      <td>Neurofibromatosis</td>\n",
       "      <td>195-199.99</td>\n",
       "      <td>neoplasms</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34115</th>\n",
       "      <td>Q85.0</td>\n",
       "      <td>Neurofibromatosis (nonmalignant)</td>\n",
       "      <td>199.4</td>\n",
       "      <td>Neurofibromatosis</td>\n",
       "      <td>195-199.99</td>\n",
       "      <td>neoplasms</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34116</th>\n",
       "      <td>Q85.01</td>\n",
       "      <td>Neurofibromatosis, type 1</td>\n",
       "      <td>199.4</td>\n",
       "      <td>Neurofibromatosis</td>\n",
       "      <td>195-199.99</td>\n",
       "      <td>neoplasms</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34118</th>\n",
       "      <td>Q85.00</td>\n",
       "      <td>Neurofibromatosis, unspecified</td>\n",
       "      <td>199.4</td>\n",
       "      <td>Neurofibromatosis</td>\n",
       "      <td>195-199.99</td>\n",
       "      <td>neoplasms</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      icd10cm                       icd10cm_str  phecode        phecode_str  \\\n",
       "34114  Q85.02         Neurofibromatosis, type 2    199.4  Neurofibromatosis   \n",
       "34115   Q85.0  Neurofibromatosis (nonmalignant)    199.4  Neurofibromatosis   \n",
       "34116  Q85.01         Neurofibromatosis, type 1    199.4  Neurofibromatosis   \n",
       "34118  Q85.00    Neurofibromatosis, unspecified    199.4  Neurofibromatosis   \n",
       "\n",
       "      exclude_range exclude_name  leaf  rollup  \n",
       "34114    195-199.99    neoplasms   1.0     1.0  \n",
       "34115    195-199.99    neoplasms   1.0     1.0  \n",
       "34116    195-199.99    neoplasms   1.0     1.0  \n",
       "34118    195-199.99    neoplasms   1.0     1.0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_phecodes[df_phecodes['icd10cm_str'].str.contains(\"Neurofibromatosis\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afec611a-3680-41b8-a3d1-5e649533020e",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = \"lab.icd10_to_phecode\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        bigquery.SchemaField(\"icd10cm\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"icd10cm_str\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"phecode_str\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"exclude_range\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"exclude_name\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    ],\n",
    "    # Optionally, set the write disposition. BigQuery appends loaded rows\n",
    "    # to an existing table by default, but with WRITE_TRUNCATE write\n",
    "    # disposition it replaces the table with the loaded data.\n",
    "    write_disposition=\"WRITE_TRUNCATE\",  # -- we do want to replace this table if it ever is updated\n",
    ")\n",
    "\n",
    "# job = client.load_table_from_dataframe(\n",
    "#     df_phecodes, table_id, job_config=job_config\n",
    "# )  # Make an API request.\n",
    "# job.result()  # Wait for the job to complete."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d8219e-8eb1-4bc2-b7d5-2227a678f8b0",
   "metadata": {},
   "source": [
    "## Create a table containing all patient dx as phecodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32e4233d-7603-4a90-aead-6fb242e768be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pat_id          object\n",
       "dx_source       object\n",
       "icd10cm         object\n",
       "icd10cm_str     object\n",
       "phecode        float64\n",
       "phecode_str     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create the table for patient phecodes\n",
    "table_all_patients = \"arcus.patient\"\n",
    "df_patient_phecodes = mapProcReqToPheCodes(table_all_patients)\n",
    "df_patient_phecodes.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2d524bd-a39d-4e70-b343-efefb9a3e3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_id = \"lab.patient_phecode_dx\"\n",
    "\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # Specify a (partial) schema. All columns are always written to the\n",
    "    # table. The schema is used to assist in data type definitions.\n",
    "    schema=[\n",
    "        # Specify the type of columns whose type cannot be auto-detected. For\n",
    "        # example the \"title\" column uses pandas dtype \"object\", so its\n",
    "        # data type is ambiguous.\n",
    "        bigquery.SchemaField(\"pat_id\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"dx_source\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"icd10cm\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"icd10cm_str\", bigquery.enums.SqlTypeNames.STRING),\n",
    "        bigquery.SchemaField(\"phecode_str\", bigquery.enums.SqlTypeNames.STRING),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# job = client.load_table_from_dataframe(\n",
    "#     df_patient_phecodes, table_id, job_config=job_config\n",
    "# )  # Make an API request.\n",
    "# job.result()  # Wait for the job to complete.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a02a6e6-8ae7-4302-877c-5c463b7b3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertExcludeDxCsvToSql(fn):\n",
    "    # Load the dx filter file\n",
    "    df = pd.read_csv(fn)\n",
    "    # Check that the filter file has the columns we expect it to have, namely include/exclude (with specific types) and phecode\n",
    "    assert \"exclude_or_include_AAB_TS\" in list(df)\n",
    "    assert \"phecode\" in list(df)\n",
    "    # Get only the codes we want to exclude\n",
    "    dx_exclude = list(set(df[df['exclude_or_include_AAB_TS'] == \"exclude\"]['phecode']))\n",
    "    # Start the query\n",
    "    q = \"with exclude_table as (select pat_id, phecode from lab.patient_phecode_dx where \"\n",
    "    # For each exclude row, \n",
    "    for dx in dx_exclude:\n",
    "        q += \"phecode = \"+str(dx)+\" or \"\n",
    "        \n",
    "    # After iterating through the rows, remove the last \"or \"\n",
    "    q = q[:-3] +\")\"\n",
    "    \n",
    "    # Return the filter query\n",
    "    return q\n",
    "    \n",
    "fnExCodes = \"/home/youngjm/bgdlab/code/filter-scans-by-dx/dx-filters/phecodes_with_exclusion_TS_and_AAB_19April2024.csv\"\n",
    "q_dx_filter = convertExcludeDxCsvToSql(fnExCodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d5d659-50d7-4256-b60a-0039240f14b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to update an existing query to incorporate the dx filter\n",
    "def addDxFilterToQuery(fn_query, q_dx_filter):\n",
    "\n",
    "    with open(fn_query, 'r') as f:\n",
    "        q_project = f.read()\n",
    "\n",
    "    # If there is a dx filter, incorporate it into the loaded query\n",
    "    if q_dx_filter != \"\":\n",
    "        q_tmp = q_dx_filter + q_project.split(\"where\")[0] \n",
    "        q_tmp += \"left join exclude_table on proc_ord.pat_id = exclude_table.pat_id where exclude_table.pat_id is null and\"\n",
    "        q_tmp += q_project.split(\"where\")[1]\n",
    "\n",
    "    return q_tmp\n",
    "\n",
    "fn_query = \"./queries/start2022_ages12-20years.txt\"\n",
    "q_project = addDxFilterToQuery(fn_query, q_dx_filter)\n",
    "# print(q_project)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272eb7ac-f997-41dc-a4c7-647296522a86",
   "metadata": {},
   "source": [
    "# Now attempting to rewrite `getMoreReportsToGrade()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d541695c-c66d-4793-8cce-d67825ec80ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is expected for this function to take several minutes to run. Your patience is appreciated.\n",
      "Number of ids for project SLIP Adolescents 2504\n",
      "Number of reports that need to be validated: 0\n",
      "Number of validation reports added: 0\n",
      "10\n",
      "Number of new reports to grade: 10\n",
      "10 reports were added for grader Jenna Schabdach\n"
     ]
    }
   ],
   "source": [
    "numUsersForValidation = 2\n",
    "\n",
    "def getMoreReportsToGrade(name, project_id=\"SLIP\", numberToAdd=100):\n",
    "    # Global var declaration\n",
    "    global numUsersForValidation\n",
    "    print(\"It is expected for this function to take several minutes to run. Your patience is appreciated.\")\n",
    "    \n",
    "    # Initialize the client service\n",
    "    client = bigquery.Client()  \n",
    "    \n",
    "    # Load the config file\n",
    "    fn = \"./queries/config.json\" ## write this file\n",
    "    with open(fn, \"r\") as f:\n",
    "        project_lookup = json.load(f)\n",
    "        \n",
    "    # Get the info for the specified project\n",
    "    project_info = project_lookup[project_id]\n",
    "    queryFn = project_info['query']\n",
    "    q_dx_filter = ''\n",
    "    if 'dx_filter' in project_info:\n",
    "        # Get the name of the dx filter file\n",
    "        fn_dx_filter = project_info['dx_filter']\n",
    "        # Convert the contents of the dx filter file to a sql query\n",
    "        q_dx_filter = convertExcludeDxCsvToSql(fn_dx_filter)\n",
    "    \n",
    "    # Open the specified query file\n",
    "    with open(queryFn, 'r') as f:\n",
    "        q_project = f.read()\n",
    "        \n",
    "    # If there is a dx filter, incorporate it into the loaded query\n",
    "    if q_dx_filter != \"\":\n",
    "        q_tmp = q_dx_filter + q_project.split(\"where\")[0] \n",
    "        q_tmp += \"left join exclude_table on proc_ord.pat_id = exclude_table.pat_id where exclude_table.pat_id is null and\"\n",
    "        q_tmp += q_project.split(\"where\")[1]\n",
    "        q_project = q_tmp\n",
    "        \n",
    "    # Run the query from the specified file -- should the query itself be passed to a dx filtering option?\n",
    "    dfProject = client.query(q_project).to_dataframe()\n",
    "    # Now we have the ids of the reports we want to grade for Project project\n",
    "    projectProcIds = dfProject['proc_ord_id'].values \n",
    "    print(\"Number of ids for project\", project_id, len(projectProcIds))\n",
    "    \n",
    "    # Get the proc_ord_ids from the grader table\n",
    "    qGradeTable = \"SELECT proc_ord_id, grader_name from lab.grader_table_with_metadata where grade_category='Unique'; \"\n",
    "    dfGradeTable = client.query(qGradeTable).to_dataframe()\n",
    "    gradeTableProcIds = dfGradeTable['proc_ord_id'].values\n",
    "    userProcIds = dfGradeTable[dfGradeTable['grader_name'] == name]['proc_ord_id'].values\n",
    "    \n",
    "    # Validation: are there any reports for the project that need to be validated that name hasn't graded?\n",
    "    toAddValidation = []\n",
    "    for procId in projectProcIds: # for each proc_id in the project\n",
    "        if procId in dfGradeTable['proc_ord_id'].values: # if the proc_id report was already graded\n",
    "            graders = dfGradeTable.loc[dfGradeTable['proc_ord_id'] == procId, \"grader_name\"].values\n",
    "            gradersStr = \", \".join(graders)\n",
    "            # if the report was not graded by Coarse Text Search or the user and has not been graded N times\n",
    "            if \"Coarse Text Search\" not in gradersStr and name not in gradersStr and len(graders) < numUsersForValidation:\n",
    "                toAddValidation.append(procId)  \n",
    "            \n",
    "    # projectReportsInTable = [procId for procId in projectProcIds if procId in dfGradeTable['proc_ord_id'].values and not dfGradeTable.loc[dfGradeTable['proc_ord_id'] == procId, \"grader_name\"].str.contains(\"Coarse Text Search\").any() ]\n",
    "    # Ignore procIds rated by User name\n",
    "    print(\"Number of reports that need to be validated:\", len(toAddValidation))\n",
    "    toAddValidation = [procId for procId in toAddValidation if procId not in userProcIds][:numberToAdd]\n",
    "    print(\"Number of validation reports added:\", len(toAddValidation))\n",
    "    print(numberToAdd)\n",
    "    \n",
    "    # Add validation reports - procIds already in the table\n",
    "    if len(toAddValidation) > 0:\n",
    "        addReportsQuery = 'insert into lab.grader_table_with_metadata (proc_ord_id, grader_name, grade, grade_category, pat_id, age_in_days, proc_ord_year, proc_name, report_origin_table, project, grade_date) VALUES '\n",
    "        for procId in toAddValidation[:numberToAdd]:\n",
    "            row = dfProject[dfProject['proc_ord_id'] == procId]\n",
    "            addReportsQuery += '(\"'+str(procId)+'\", \"'+name+'\", 999, \"Unique\", \"'\n",
    "            addReportsQuery += row['pat_id'].values[0]+'\", '+str(row['proc_ord_age'].values[0])\n",
    "            addReportsQuery += ', '+str(row['proc_ord_year'].values[0])+', \"'+str(row['proc_ord_desc'].values[0].replace(\"'\", \"\\'\"))\n",
    "            addReportsQuery += '\", \"arcus.procedure_order\", \"'+project_id+'\", \"0000-00-00\"), '\n",
    "        print(len(toAddValidation[:numberToAdd]))\n",
    "        addReportsQuery = addReportsQuery[:-2]+\";\"\n",
    "        addingReports = client.query(addReportsQuery)\n",
    "        addingReports.result()\n",
    "\n",
    "    # New reports\n",
    "    toAddNew = [procId for procId in projectProcIds if procId not in dfGradeTable['proc_ord_id'].values][:(numberToAdd - len(toAddValidation))]\n",
    "    \n",
    "    # Add new reports\n",
    "    print(\"Number of new reports to grade:\", len(toAddNew))\n",
    "    if len(toAddNew) > 0:\n",
    "        addReportsQuery = 'insert into lab.grader_table_with_metadata (proc_ord_id, grader_name, grade, grade_category, pat_id, age_in_days, proc_ord_year, proc_name, report_origin_table, project, grade_date) VALUES '\n",
    "        for procId in toAddNew:\n",
    "            row = dfProject[dfProject['proc_ord_id'] == procId]\n",
    "            addReportsQuery += '(\"'+str(procId)+'\", \"'+name+'\", 999, \"Unique\", \"'\n",
    "            addReportsQuery += row['pat_id'].values[0]+'\", '+str(row['proc_ord_age'].values[0])\n",
    "            addReportsQuery += ', '+str(row['proc_ord_year'].values[0])+', \"'+str(row['proc_ord_desc'].values[0].replace(\"'\", \"\\'\"))\n",
    "            addReportsQuery += '\", \"arcus.procedure_order\", \"'+project_id+'\", \"0000-00-00\"), '\n",
    "        addReportsQuery = addReportsQuery[:-2]+\";\"\n",
    "        addingReports = client.query(addReportsQuery)\n",
    "        addingReports.result()\n",
    "    \n",
    "    # Check: how many reports were added for the user?\n",
    "    if (len(toAddValidation) + len(toAddNew)) == 0:\n",
    "        print(\"There are no reports returned by the specified query that have yet to be either graded or validated.\")\n",
    "    else:\n",
    "        getUserUnratedCount = 'SELECT * FROM lab.grader_table_with_metadata WHERE grader_name like \"' + name + '\" and grade = 999'\n",
    "\n",
    "        df = client.query(getUserUnratedCount).to_dataframe()\n",
    "\n",
    "        # Inform the user\n",
    "        print(len(df), \"reports were added for grader\", name)\n",
    "\n",
    "getMoreReportsToGrade(\"Jenna Schabdach\", project_id=\"SLIP Adolescents\", numberToAdd=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3883213d-9cb2-4604-8c4b-de9348bc0111",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "dict_config = { \"SLIP Adolescents\": {\n",
    "                    \"query\": \"./queries/start2022_ages12-20years.txt\",\n",
    "                    \"dx_filter\": \"/home/youngjm/bgdlab/code/filter-scans-by-dx/dx-filters/phecodes_with_exclusion_TS_and_AAB_19April2024.csv\"\n",
    "                },\n",
    "                \"SLIP\": {\n",
    "                    \"query\": \"./queries/slip_base.txt\",\n",
    "                    \"dx_filter\": \"/home/youngjm/bgdlab/code/filter-scans-by-dx/dx-filters/phecodes_with_exclusion_TS_and_AAB_19April2024.csv\"\n",
    "                },\n",
    "                \"SLIP PreK\": {\n",
    "                    \"query\": \"./queries/start2018_ages2-5years.txt\",\n",
    "                    \"dx_filter\": \"\"\n",
    "                },\n",
    "                \"Clinical Imaging Genetics\": {\n",
    "                    \"query\": \"./queries/clinical_imaging_genetics.txt\",\n",
    "                    \"dx_filter\": \"\" \n",
    "                }\n",
    "              }\n",
    "\n",
    "with open(\"./queries/config.json\", 'w') as fp:\n",
    "    json.dump(dict_config, fp, indent=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7722c0b1-819f-4540-9d5b-0914e3a097ba",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3b99f5c8-cc95-4455-a97d-0be54a01c628",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 1)\n"
     ]
    }
   ],
   "source": [
    "## Test - does that filter part of the query plus other stuff give \n",
    "# the same number of patients in the SLIP requests that can be recruited \n",
    "# for BBG?\n",
    "# It should just be \"get everything from table not in dx filter\"\n",
    "table = \"lab.session_request_2023_09_with_metadata\"\n",
    "q = q_dx_filter + \" select distinct req.pat_id from \"+table+\" req left join exclude_table \"\n",
    "q += \" on req.pat_id = exclude_table.pat_id \"\n",
    "q += \" where\"\n",
    "q += \" exclude_table.pat_id is null \"\n",
    "# Adding in age/scan year filter\n",
    "q += \" and proc_ord_year = 2023 \"\n",
    "q += \" and proc_ord_age > 12*365 \"\n",
    "q += \" and proc_ord_age < 21*365 \"\n",
    "    \n",
    "# print(q)\n",
    "# Do the query\n",
    "df_test = client.query(q).to_dataframe()\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0d5b816-eaf8-4561-8a55-35c3f02ccb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 17)\n"
     ]
    }
   ],
   "source": [
    "df_nov_req = client.query(\"select * from lab.2023_09_slip_adolescent_prospective_filtereddx_2024_04_updated ;\").to_dataframe()\n",
    "print(df_nov_req.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bde600-1eb5-493a-a015-1b50cb5a2858",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3-read-only",
   "language": "python",
   "name": "conda-env-python3-read-only-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
